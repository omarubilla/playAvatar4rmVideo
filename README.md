# Video to Playable Avatars in 3D Gaming Environment
![](https://img.shields.io/static/v1?label=python&message=3.6|3.7&color=blue)
![](https://img.shields.io/static/v1?label=pytorch&message=1.4&color=<COLOR>)
[![](https://img.shields.io/static/v1?label=license&message=BSD3&color=green)](./License.txt)

by Artem Tikhonov, Kevin Ubilla et al.

## Step 1: Import MP4 File

## Step 2: Map Scene to 3D Environment

## Step 3: Add Playable Avatar 

## Step 4: Controls: Zoom/Pan/Switch Player/Next Play 


# In The News
![Stanford Daily Article](stanfordDailyArticle2.png?raw=true)

[Stanford Daily Article](https://stanforddaily.com/2022/10/20/ubilla-m-s-26-seeks-to-revolutionize-sports-with-augmented-reality/)


# Acknowledgements

This work was created with guidance from Jiaman Li and Yifeng Jiang, PhD students at [Stanford's Movement Lab](https://tml.stanford.edu/).

We are grateful for proffesor Karen Liu's mentorhip, along with the greater [Wu Tsai Human Performance Alliance](https://humanperformancealliance.org/) and the [Wearable Electronics Initiative](https://wearable.su.domains/) communities at Stanford University.

Demo videos and prototyping was first conducted at De Anza College in Cupertino, CA. [Apple Founders-De Anza Alumni](https://apple.fandom.com/wiki/De_Anza_College)

# References
This repository is built on top of the following repositories:
* Learning Physically Simulated Tennis Skills from Broadcast Videos [Hoatian Zhang](https://github.com/nv-tlabs/vid2player3d)
* Controllable Character Video Synthesis with Spatial Decomposed Modeling [MIMO](https://github.com/menyifang/MIMO)
    
## Contact
Kevin Ubilla kevin@elisxr.com | 
www.elisxr.ai
